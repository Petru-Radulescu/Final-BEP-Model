{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.stats.power as smp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let scientists compete against each other throughout their entire lifespan\n",
    "def competition(lifeSpan, sampleSize, scientistPerQuestionMax, startupCost, sampleCost, ExpDistributionShape, scoopedCost, negativeResultCost, limit, newQuestionCost, randomChance, chance):\n",
    "    oneYear = lifeSpan/20 # definition of one year in time units, career of scientist takes 20 years\n",
    "    scientistID = list(np.arange(populationSize)) # list with scientist IDs\n",
    "    amountOfQuestions = round((lifeSpan / (startupCost + minSampleSize)) * populationSize + populationSize) # generates number of questions\n",
    "    questionID = list(np.arange(amountOfQuestions)) # list with question IDs\n",
    "    effectSizeQuestion = list(np.round(np.array(np.random.exponential(1/ExpDistributionShape, size=amountOfQuestions)), 1)) # list with effect sizes drawn from a uniform distribution\n",
    "    drawerQ = list(np.array(np.zeros(shape=[populationSize, 0]),np.int32)) # integer list of completed question IDs indexed by scientist ID\n",
    "    drawerR = list(np.array(np.zeros(shape=[populationSize, 0]),np.bool_)) # boolean list of completed question results indexed by scientist ID\n",
    "    drawerP = []\n",
    "    drawerU = []\n",
    "    \n",
    "   \n",
    "    \n",
    "    if randomChance == True:\n",
    "        chanceNewQ = list(np.random.randint(0, 10, size=populationSize))\n",
    "    else:\n",
    "        chanceNewQ = chance\n",
    "    \n",
    "    # create scientist dataframe\n",
    "    d1 = {'scientistID' : scientistID, 'sampleSize' : sampleSize, 'questionID' : 0, 'publications' : 0, 'payoff' : 0.0,'chance': chanceNewQ }\n",
    "    scientistDataFrame = pd.DataFrame(data=d1)\n",
    "\n",
    "    # create results dataframe\n",
    "    d2 = {'questionID' : questionID, 'scientistID' : -1, 'sampleSize' : 0, 'effectSize': effectSizeQuestion,'result' : 0, 'published':None}\n",
    "    resultsDataFrame = pd.DataFrame(data=d2)\n",
    "    \n",
    "    \n",
    "    # question trackers\n",
    "    questionIDsPublished = [] # list of questions that have been published\n",
    "    questionIDsWorked = [] # list of questions that have been completed\n",
    "    \n",
    "    # time (cost) trackers\n",
    "    timePeriod = 1 #start\n",
    "    timeCost = list(scientistDataFrame['sampleSize'] * sampleCost + startupCost) # real-time tracker\n",
    "    timeCostBaseline = list(scientistDataFrame['sampleSize'] * sampleCost + startupCost) # baseline tracker\n",
    "    extraTimeCost = [0] * populationSize\n",
    "\n",
    "    # assign scientists to questions\n",
    "    scientistDataFrame['questionID'] = np.repeat(questionID, scientistPerQuestionMax)[:len(scientistDataFrame['scientistID'])] \n",
    "\n",
    "    # create a list that keeps track of amount of scientists on a question\n",
    "    filledQuestions = pd.crosstab(index=scientistDataFrame['questionID'], columns=\"count\") #creates df with questionid and nr of scientis working on it\n",
    "    emptyQuestions = (amountOfQuestions - len(filledQuestions)) * [0] # creates a list with 0's with len of unused questions\n",
    "    emptyQuestions = pd.DataFrame(emptyQuestions, columns=[\"count\"]) # df of question id and nr of scientis working on \n",
    "    questionDataFrame = filledQuestions.append(emptyQuestions, ignore_index= True) # combine the two df's \n",
    "    scientistPerQuestion = list(questionDataFrame['count']) #create a list of the count df\n",
    "\n",
    "    \n",
    "    yearProgress = oneYear # time to next year tracker\n",
    "    unpubQ = questionID # list of all questions that have been worked on\n",
    "    \n",
    "    while(timePeriod < lifeSpan):\n",
    "            \n",
    "        # calculate time to next event: end of year / completed research / end of lifespan\n",
    "        timeToNextEvent = min(yearProgress, min( min(timeCost), lifeSpan - timePeriod)) \n",
    "        \n",
    "        # update time trackers\n",
    "        if limit:\n",
    "            yearProgress = yearProgress - timeToNextEvent # update time to next year tracker\n",
    "        timeCost = list(timeCost - np.repeat(timeToNextEvent, len(timeCost))) # update timecost tracker for every scientist\n",
    "        timePeriod = timePeriod + timeToNextEvent # update the current model time\n",
    "        if (timePeriod > lifeSpan):\n",
    "            break\n",
    "        \n",
    "        if (min(timeCost) == 0): # studies are completed -> scientists store questions into their drawer\n",
    "            if limit == False:\n",
    "                yearProgress = 0\n",
    "            # trackers for scientists who completed a study\n",
    "            actingScientists = np.array([i for i, noTimeLeft in enumerate(timeCost) if noTimeLeft == 0]) # retrieves the indeces of people who have finished sampling\n",
    "            amountActingScientists = len(actingScientists) # count amount of scientists who have completed their study\n",
    "            questionActingScientists = list(scientistDataFrame[scientistDataFrame['scientistID'].isin(actingScientists)]['questionID']) # retrieve question IDs of questions that have been completed\n",
    "\n",
    "            # store effect sizes and sample sizes of completed questions\n",
    "            effectSizeQuestion = [] # create list for effect sizes of completed questions\n",
    "            for i in questionActingScientists: # for every completed question index\n",
    "                effectSizeQuestion.append(resultsDataFrame.loc[[i],'effectSize']) # store the effect size from the resultsDataFrame in the list of effect sizes of completed questions\n",
    "            sampleSizeActingScientists = list(scientistDataFrame[scientistDataFrame['scientistID'].isin(actingScientists)]['sampleSize']) # list of sample sizes of completed questions\n",
    "\n",
    "\n",
    "            # store statistical powers of the completed questions\n",
    "            sampleSizeIndex = 0 # sample size index tracker\n",
    "            powerOfQuestions = [] # list of powers of completed questions\n",
    "            for qid in questionActingScientists: # for every completed question\n",
    "                    resultsDataFrame.at[qid,'published'] = False\n",
    "                    powerOfQuestion =  smp.ttest_power( effect_size= resultsDataFrame._get_value(qid, 'effectSize'),\n",
    "                                                       nobs=sampleSizeActingScientists[sampleSizeIndex], \n",
    "                                                       alpha=0.05, alternative='two-sided') # calculate the power\n",
    "                    powerOfQuestions.append(powerOfQuestion) # add power to list of powers of completed questions\n",
    "                    sampleSizeIndex += 1 # increase sample size index tracker by one\n",
    "            \n",
    "            # simulate the result of a completed question based on the power\n",
    "            positiveResult = [] # list of boolean results for completed questions\n",
    "            for r in range(amountActingScientists): # for each completed question\n",
    "                positiveResult.append(np.random.uniform(0,1) < powerOfQuestions[r]) # store positive or negative result based on power and a drawn value from a uniform distribution\n",
    "            \n",
    "            for sid in actingScientists: # for every acting scientist\n",
    "                qid = questionActingScientists[np.where(actingScientists == sid)[0][0]] # retrieve the question ID they completed\n",
    "                drawerQ[sid] = np.append(drawerQ[sid], [qid]) # add question ID to drawer\n",
    "                drawerR[sid] = np.append(drawerR[sid], [positiveResult[np.where(actingScientists == sid)[0][0]]]) # add question result to drawer\n",
    "            # update completed question tracker\n",
    "            questionIDsWorked = np.concatenate((questionIDsWorked, questionActingScientists)) # add completed questions to the tracker\n",
    "            \n",
    "            # update the results dataframe \n",
    "            for sid in actingScientists: # for every scientist that completed a question\n",
    "                qid = questionActingScientists[np.where(actingScientists == sid)[0][0]] # retrieve the question ID they completed\n",
    "                resultsDataFrame.loc[[qid],'scientistID'] = sid # add scientist ID to results dataframe\n",
    "                resultsDataFrame.loc[[qid],'sampleSize'] = sampleSizeActingScientists[np.where(actingScientists == sid)[0][0]] # add sample size to results dataframe\n",
    "                resultsDataFrame.loc[[qid],'result'] = positiveResult[np.where(actingScientists == sid)[0][0]] # add result to results dataframe\n",
    "\n",
    "            # find assignable questions and assign scientists to a new question\n",
    "            for sid in actingScientists: # for every scientist\n",
    "                nextQuestion = np.random.choice(unpubQ)\n",
    "                if resultsDataFrame.loc[[qid],'effectSize'].item() > resultsDataFrame.loc[[nextQuestion],'effectSize'].item() and scientistDataFrame.loc[[sid],'chance'].item() != 0:\n",
    "                    if  np.random.choice(scientistDataFrame.loc[[sid],'chance'].item(), 1) == 0:\n",
    "                        nextQuestion = np.random.choice(unpubQ)\n",
    "                        extraTimeCost[sid] = extraTimeCost[sid] + newQuestionCost\n",
    "            \n",
    "                scientistPerQuestion[qid] -= 1 # decrease number of scientist working on the completed question by one\n",
    "                scientistPerQuestion[nextQuestion] += 1 # increase number of scientist working on the next question by one\n",
    "                scientistDataFrame.loc[[\n",
    "                    resultsDataFrame.loc[[qid],'scientistID'].item()], 'questionID'] = nextQuestion # update scientist dataframe with the new question ID\n",
    "\n",
    "            # adjust the baseline\n",
    "            for sid in actingScientists: # for every scientist\n",
    "                timeCost[sid] = timeCostBaseline[sid] + extraTimeCost[sid]  # reset their time cost to the baseline value\n",
    "            \n",
    "            extraTimeCost = [0] * populationSize\n",
    "                \n",
    "        elif yearProgress == 0: # end of year -> scientists publish their papers\n",
    "            yearProgress = oneYear # reset time to next year tracker\n",
    "            \n",
    "            for sid in np.repeat(scientistDataFrame['scientistID'], paperLimit): # for each scientist\n",
    "                workedQ = drawerQ[sid] # retrieve all completed, unpublished questions from their drawer\n",
    "                if len(workedQ) != 0: # if their drawer is not empty\n",
    "                    payoff = 0 # initialize payoff\n",
    "                    \n",
    "                    # find question with highest payoff in a scientist's drawer and publish it\n",
    "                    for q in range(len(workedQ)): # for each completed, unpublished question\n",
    "                        priorPublished = questionIDsPublished.count(workedQ[q]) # count prior published works on this question\n",
    "                        noveltyResult = pow( (1/(1+priorPublished)), scoopedCost) # calculate novelty of this question based on novelty and scooping cost\n",
    "                        if drawerR[sid][q]: # if the result of the completed, unpublished question is positive \n",
    "                            possiblepayoff = noveltyResult # the possible payoff is equal to the payoff of a novel result\n",
    "                        else: # if the result of the completed, unpublished question is negative\n",
    "                            possiblepayoff = noveltyResult * negativeResultCost # the possible payoff is equal to the payoff of a novel result scaled down with the cost of a negative result\n",
    "                        if possiblepayoff > payoff: # if a completed, unpublished question is found with a higher possible payoff than the current stored payoff\n",
    "                            tempq = q # question to publish becomes the current completed, unpublished question\n",
    "                            payoff = possiblepayoff # payoff becomes the highest possible payoff\n",
    "                    payoff = np.round(payoff,2) # round payoff to two decimals\n",
    "                    # publish question with the highest possible payoff\n",
    "                    scientistDataFrame.at[sid, 'payoff'] = scientistDataFrame.at[sid, 'payoff'].astype(float) + payoff # add payoff to scientist's previous payoffs\n",
    "                    scientistDataFrame.at[sid, 'publications'] = scientistDataFrame.at[sid, 'publications'].astype(int) + 1 # increase number of scientist's publications by one\n",
    "                    questionIDsPublished.append(drawerQ[sid][tempq]) # add now published question to the list of published questions\n",
    "                    resultsDataFrame.at[drawerQ[sid][tempq],'published'] = True # change published status to True\n",
    "                    \n",
    "                    drawerP.append([resultsDataFrame.loc[[drawerQ[sid][tempq]],'effectSize'].item(),drawerR[sid][tempq]])\n",
    "                    \n",
    "                    # remove the completed, published question from the drawer of completed, unpublished questions\n",
    "                    if drawerQ[sid][tempq] in unpubQ:\n",
    "                        unpubQ.remove(drawerQ[sid][tempq])\n",
    "                    drawerQ[sid] = np.delete(drawerQ[sid], tempq) # remove question from drawer with question IDs\n",
    "                    drawerR[sid] = np.delete(drawerR[sid], tempq) # remove question from drawer with question results\n",
    "                    \n",
    "    \n",
    "    for sid in scientistDataFrame['scientistID']:\n",
    "        for q in range(len(drawerQ[sid])):\n",
    "            drawerU.append([resultsDataFrame.loc[[drawerQ[sid][q]],'effectSize'].item(),drawerR[sid][q]])\n",
    "        \n",
    "    publishedDataFrame = pd.DataFrame(data=drawerP, columns = ['effectSize','result'])\n",
    "    unpublishedDataFrame = pd.DataFrame(data=drawerU, columns = ['effectSize','result'])\n",
    "    finishedDataFrame =  resultsDataFrame[(resultsDataFrame['published'] == True) | (resultsDataFrame['published'] == False)].reset_index() # store all finished questions in dataframe  \n",
    "          \n",
    "\n",
    "    return scientistDataFrame , resultsDataFrame, finishedDataFrame, drawerQ, publishedDataFrame, unpublishedDataFrame  # return scientist dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run generations of scientists that compete against each other and evolve\n",
    "def evolution(lifeSpan, scientistPerQuestionMax, generations, startupCost, sampleCost, ExpDistributionShape, scoopedCost, negativeResultCost, limit, newQuestionCost, randomChance, chance):\n",
    "    \n",
    "    for run in range(10):\n",
    "        print('Run: '+ str(run))\n",
    "        \n",
    "        # initialize population\n",
    "        sampleSize = np.round(np.random.uniform(minSampleSize, maxSampleSize, populationSize)) # draw sample sizes from a uniform distribution\n",
    "        meanSampleSizes = []   # list of mean sample sizes\n",
    "        meanPayoffs = []       # list of mean payoffs\n",
    "        meanPublished = []     # list of mean number of published questions\n",
    "        maxQ = []             # list of mean question IDs\n",
    "        meanChance = []\n",
    "        percFalsePosAll = []   # list of percentages of false positives (all finished questions)\n",
    "        percFalsePosPub = []   # list of percentages of false positives (all published questions)\n",
    "        percFalsePosUnpub = [] # list of percentages of false positives (all unpublished questions)\n",
    "        percFalseNegAll = []   # list of percentages of false negatives (all finished questions)\n",
    "        percFalseNegPub = []   # list of percentages of false negatives (all published questions)\n",
    "        percFalseNegUnpub = [] # list of percentages of false negatives (all unpublished questions)\n",
    "        generationsPlot = (np.arange(generations)) + 1 \n",
    "        drawerSizes = []\n",
    "        percPosPublished = []\n",
    "        trackFalsePos = []\n",
    "        trackFalseNeg = []\n",
    "        trackFalsePosPub = []\n",
    "        trackFalseNegPub = []\n",
    "\n",
    "\n",
    "        for g in range(generations): # for every generation \n",
    "            print(\"working on generation: \",g+1,\"/\",generations)\n",
    "            result = competition(lifeSpan, sampleSize, scientistPerQuestionMax, startupCost, sampleCost, \n",
    "                                          ExpDistributionShape, scoopedCost, negativeResultCost, limit, newQuestionCost, randomChance, chance) # return scientist dataframe\n",
    "            outcomeGeneration = result[0]\n",
    "            # allocate new generation of scientists a sample size with payoffs of their predecessors as (probability) weights\n",
    "            sampleSize = outcomeGeneration.sample(n=populationSize, weights='payoff', random_state=1, replace= True)['sampleSize'].to_numpy() \n",
    "            chance = outcomeGeneration.sample(n=populationSize, weights='payoff', random_state=1, replace= True)['chance'].to_numpy()\n",
    "\n",
    "            for s in range(len(sampleSize)): # for each sample size\n",
    "                sampleSize[s] = np.absolute(np.round(np.random.normal(sampleSize[s], 1.5, 1))) # introduce noise\n",
    "\n",
    "            meanSampleSizes.append(outcomeGeneration[\"sampleSize\"].mean()) # add mean sample size to list of mean sample sizes\n",
    "            meanPayoffs.append(outcomeGeneration[\"payoff\"].mean())         # add mean payoff to list of mean payoffs\n",
    "            meanPublished.append(outcomeGeneration[\"publications\"].mean()) # add mean number of published questions to list of mean number of published questions\n",
    "            maxQ.append(outcomeGeneration[\"questionID\"].max())           # add mean question ID to list of mean question IDs\n",
    "            meanChance.append(outcomeGeneration[\"chance\"].mean())\n",
    "\n",
    "            finishedDataFrame = result[2] # retrieve finished questions dataframe\n",
    "\n",
    "            published = result[4]\n",
    "            #print(published)\n",
    "            unpublished = result[5]\n",
    "            frames = [published, unpublished]\n",
    "            allResearched = pd.concat(frames)\n",
    "\n",
    "            # calculating false positive and false negative rates for all finished questions\n",
    "            lenFinished = len(allResearched) # number of finished questions\n",
    "            falsePosAll = (allResearched['effectSize'] == 0.0) & (allResearched['result'] == True) # false positive boolean mask\n",
    "            falseNegAll = (allResearched['effectSize'] > 0.0) & (allResearched['result'] == False) # false negative boolean mask\n",
    "            nrFalsePosAll = allResearched[falsePosAll].count()[0] # number of false positives\n",
    "            nrFalseNegAll = allResearched[falseNegAll].count()[0] # number of false negatives\n",
    "            percFalsePosAll.append((nrFalsePosAll/lenFinished)*100) # add false positive percentage to list of false positives\n",
    "            percFalseNegAll.append((nrFalseNegAll/lenFinished)*100) # add false negative percentage to list of false negatives\n",
    "\n",
    "            # calculating false positive and false negative rates for all published questions\n",
    "            lenFinishedPub = len(published) # number of published questions\n",
    "            falsePosPub = (published['effectSize'] == 0.0) & (published['result'] == True) # false positive boolean mask\n",
    "            falseNegPub = (published['effectSize'] > 0.0) & (published['result'] == False) # false positive boolean mask # false negative boolean mask\n",
    "            nrFalsePosPub= published[falsePosPub].count()[0] # number of false positives\n",
    "            nrFalseNegPub = published[falseNegPub].count()[0] # number of false negatives\n",
    "            percFalsePosPub.append((nrFalsePosPub/lenFinishedPub)*100) # add false positive percentage to list of false positives\n",
    "            percFalseNegPub.append((nrFalseNegPub/lenFinishedPub)*100) # add false negative percentage to list of false negatives\n",
    "\n",
    "            # calculating false positive and false negative rates for all unpublished questions\n",
    "            lenFinishedUnpub = len(unpublished) # number of unpublished questions\n",
    "            falsePosUnpub = (unpublished['effectSize'] == 0.0) & (unpublished['result'] == True) # false positive boolean mask\n",
    "            falseNegUnpub = (unpublished['effectSize'] > 0.0) & (unpublished['result'] == False) # false negative boolean mask\n",
    "            nrFalsePosUnpub = unpublished[falsePosUnpub].count()[0] # number of false positives\n",
    "            nrFalseNegUnpub = unpublished[falseNegUnpub].count()[0] # number of false negatives\n",
    "            if lenFinishedUnpub > 0:\n",
    "                percFalsePosUnpub.append((nrFalsePosUnpub/lenFinishedUnpub)*100) # add false positive percentage to list of false positives\n",
    "                percFalseNegUnpub.append((nrFalseNegUnpub/lenFinishedUnpub)*100) # add false negative percentage to list of false negatives\n",
    "            else:\n",
    "                percFalsePosUnpub.append(0) # add false positive percentage to list of false positives\n",
    "                percFalseNegUnpub.append(0) # add false negative percentage to list of false negatives\n",
    "\n",
    "            #printProgressNew = outcomeGeneration[['sampleSize','payoff', 'publications']] \n",
    "            #printProgress = pd.concat([printProgress, printProgressNew], axis=1)\n",
    "            #print(outcomeGeneration)\n",
    "\n",
    "            trackFalsePos.append(nrFalsePosAll)\n",
    "            trackFalseNeg.append(nrFalseNegAll)\n",
    "            trackFalsePosPub.append(nrFalsePosPub)\n",
    "            trackFalseNegPub.append(nrFalseNegPub)\n",
    "\n",
    "            positives = np.sum(published['result'] == True)\n",
    "            #print(positives)\n",
    "            resultsTotal = len(published)\n",
    "            if resultsTotal != 0:\n",
    "                percPosPublished.append(100 * np.round((positives / resultsTotal), 2))\n",
    "            else:\n",
    "                percPosPublished.append(0)\n",
    "\n",
    "            drawerSize = 0\n",
    "            drawer = result[3]\n",
    "            for i in range(populationSize):\n",
    "                drawerSize += len(drawer[i])\n",
    "            drawerSizes.append(drawerSize)\n",
    "\n",
    "            ##outcomeGeneration.to_csv('file' + str(g) +'.csv')\n",
    "\n",
    "\n",
    "        # plot mean payoff, mean sample size, mean number of published questions and mean question ID against generations\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "\n",
    "        fig.suptitle('Progression with limit set to {}'.format(limit))\n",
    "        axs[0].plot(generationsPlot, meanPayoffs, 'tab:orange')\n",
    "        axs[0].set_title('Mean Payoffs')\n",
    "        axs[0].set(ylim=(0, max(meanPayoffs)+max(meanPayoffs)/10))\n",
    "\n",
    "        axs[1].plot(generationsPlot, meanSampleSizes,  'tab:green')\n",
    "        axs[1].set_title('Mean SampleSize')\n",
    "        axs[1].set(ylim=(0, max(meanSampleSizes)+max(meanSampleSizes)/10))\n",
    "\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        fig.suptitle( \"Progression, limit = {}\".format(limit) )\n",
    "\n",
    "        axs[1].plot(generationsPlot, meanPublished, 'tab:red')\n",
    "        axs[1].set_title('Mean Published')\n",
    "        axs[1].set(ylim=(0, max(meanPublished)+max(meanPublished)/10))\n",
    "\n",
    "        axs[0].plot(generationsPlot, maxQ, 'tab:orange')\n",
    "        axs[0].set_title('Questions worked on')\n",
    "        axs[0].set(ylim=(0, round((lifeSpanT / (startupCostT + minSampleSize)) * populationSize + populationSize)))\n",
    "\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        fig.suptitle('All finished questions, limit = {}'.format(limit) )\n",
    "        axs[0].plot(generationsPlot, percFalsePosAll, 'tab:green')\n",
    "        axs[0].set_title('Percentage False Positives')\n",
    "        axs[0].set(ylim=(0, 101))\n",
    "\n",
    "        axs[1].plot(generationsPlot, percFalseNegAll, 'tab:red')\n",
    "        axs[1].set_title('Percentage False Negatives')\n",
    "        axs[1].set(ylim=(0, 101))\n",
    "\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        fig.suptitle('All published questions, limit = {}'.format(limit))\n",
    "        axs[0].plot(generationsPlot, percFalsePosPub, 'tab:green')\n",
    "        axs[0].set_title('Percentage False Positives')\n",
    "        axs[0].set(ylim=(0, 101))\n",
    "\n",
    "        axs[1].plot(generationsPlot, percFalseNegPub, 'tab:red')\n",
    "        axs[1].set_title('Percentage False Negatives')\n",
    "        axs[1].set(ylim=(0, 101))\n",
    "\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        fig.suptitle('All unpublished questions, limit = {}'.format(limit))\n",
    "        axs[0].plot(generationsPlot, percFalsePosUnpub, 'tab:green')\n",
    "        axs[0].set_title('Percentage False Positives')\n",
    "        axs[0].set(ylim=(0, 101))\n",
    "\n",
    "        axs[1].plot(generationsPlot, percFalseNegUnpub, 'tab:red')\n",
    "        axs[1].set_title('Percentage False Negatives')\n",
    "        axs[1].set(ylim=(0, 101))\n",
    "\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        fig.suptitle('File-drawer, limit = {}'.format(limit))\n",
    "        axs[0].plot(generationsPlot, drawerSizes, 'tab:red')\n",
    "        axs[0].set_title('Papers file-drawer')\n",
    "        axs[0].set(ylim=(0, max(drawerSizes)+10))\n",
    "\n",
    "        axs[1].plot(generationsPlot, percPosPublished, 'tab:red')\n",
    "        axs[1].set_title('% positive published results')\n",
    "        axs[1].set(ylim=(0, 101))\n",
    "\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "\n",
    "        fig.suptitle('Mean chace'.format(limit))\n",
    "        axs[0].plot(generationsPlot, meanChance, 'tab:orange')\n",
    "        axs[0].set_title('Mean chace')\n",
    "        axs[0].set(ylim=(0, max(meanChance)+max(meanChance)/10))\n",
    "\n",
    "        d5 = {'FP all': trackFalsePos, 'FN all' : trackFalseNeg, 'FP pub': trackFalsePosPub, 'FN pub': trackFalseNegPub }\n",
    "        falseDataframe = pd.DataFrame(data=d5)\n",
    "        print(falseDataframe)\n",
    "\n",
    "\n",
    "        meanSampleSizeOverRuns.append(meanSampleSizes)\n",
    "        meanPayoffsOverRuns.append(meanPayoffs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanSampleSizeOverRuns = []\n",
    "meanPayoffsOverRuns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#number of scientists\n",
    "populationSize = 120\n",
    "\n",
    "#Scientists initial sample sizes \n",
    "minSampleSize = 2\n",
    "maxSampleSize = 1000\n",
    "\n",
    "# T = Test variable\n",
    "lifeSpanT = 15000\n",
    "scientistPerQuestionMaxT = 1\n",
    "startupCostT = 125\n",
    "sampleCostT = 1\n",
    "ExpDistributionShapeT = 8\n",
    "scoopedCostT = 0.5\n",
    "negativeResultCostT = 0.5\n",
    "paperLimit = 1\n",
    "limit = True\n",
    "newQuestionCost = 0\n",
    "randomChance = False\n",
    "chance = 0\n",
    "\n",
    "generationsT = 100\n",
    "\n",
    "# for x in range(2):\n",
    "#     print(\"limit is {}\".format(limit))\n",
    "#     evolution (lifeSpanT, scientistPerQuestionMaxT, generationsT, startupCostT, sampleCostT, ExpDistributionShapeT, scoopedCostT, negativeResultCostT, limit)\n",
    "#     limit = not limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "limit = True\n",
    "evolution (lifeSpanT, scientistPerQuestionMaxT, generationsT, startupCostT, sampleCostT, ExpDistributionShapeT, scoopedCostT, negativeResultCostT, limit, newQuestionCost, randomChance, chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "limit = False\n",
    "evolution (lifeSpanT, scientistPerQuestionMaxT, generationsT, startupCostT, sampleCostT, ExpDistributionShapeT, scoopedCostT, negativeResultCostT, limit, newQuestionCost, randomChance, chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanSamplesDataFrame = pd.DataFrame(data = meanSampleSizeOverRuns)\n",
    "print(meanSamplesDataFrame)\n",
    "meanPayoffDataFrame = pd.DataFrame(data = meanPayoffsOverRuns)\n",
    "print(meanPayoffDataFrame)\n",
    "meanSamplesDataFrame.to_csv('meanSamplesDataFrame.csv')\n",
    "meanPayoffDataFrame.to_csv('meanPayoffDataFrame.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "09252b4e88fa85a0493145ce2e96115e8729ccb750fcebda0a5a24f7f8e19bfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
